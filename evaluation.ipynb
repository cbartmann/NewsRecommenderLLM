{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.221)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (1.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.9.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (2.6.2)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.2.9)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.23.6)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.2)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.2)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.17.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.3)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.7.4)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain ipywidgets pandas ipywidgets\n",
    "!pip install faiss-cpu --no-cache\n",
    "!pip install tiktoken\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credentials(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    lines = content.split('\\n')\n",
    "    username = lines[0].split(': ')[1]\n",
    "    api_key = lines[1].split(': ')[1]\n",
    "\n",
    "    username = username.strip()\n",
    "    api_key = api_key.strip()\n",
    "\n",
    "    return username, api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "username, api_key = load_credentials('Data/Key.txt')\n",
    "openai.api_key = api_key\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Pipeline for the Recommender System\n",
    "\n",
    "This notebook establishes the necessary ingredinets for the evaluation pipeline for our recommender prototype. The design is inspired by both LangChain documentation and OpenAI's evals repository. It is relatively clear that the challenge in the evaluation is the lack of ground truth values. Thus we utilize the functionality of large language models (LLMs) to evaluate our model.\n",
    "\n",
    "The notebook is divided into two main parts:\n",
    "\n",
    "## Part 1: Query Development \n",
    "\n",
    "In this section, we develop queries from 100 randomly selected articles. For each article, we generate two types of queries:\n",
    "\n",
    "1. **General queries**: These queries are derived from the broad information of the specific news article. And are supposed to only capture the general topics that the specific news article captures.\n",
    "2. **Specific queries**: These queries are closely tied to the content of the specific news article. \n",
    "\n",
    "These queries will later be used in the recommender system to verify if it suggests the original news article from which the query was derived.\n",
    "\n",
    "## Part 2: Evaluation of Recommender System Responses \n",
    "\n",
    "This part of the notebook deals with the evaluation of the recommender system's responses. The idea is to use the LLM to determine whether a suggestion is relevant to the specific query. To achieve this, we develop an eval chain and validate it using the previously generated queries.\n",
    "\n",
    "We develop two different system prompts:\n",
    "\n",
    "1. **Normal eval system**: A stricter system.\n",
    "2. **Relaxed eval system**: A more lenient system.\n",
    "\n",
    "Based on the evaluation chain, the general queries achieved a relevance score of 88 on the normal eval system and 99 on the relaxed one. Similarly, the specific queries achieved a relevance score of 97 and 98, respectively.\n",
    "\n",
    "Thus, this system can now be utilized in the recommender system for evaluation purposes. However, please keep in mind that each evaluation run incurs a cost, as we use the LLM and send it the entire information of the article, which can be costly.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Query Formulation\n",
    "\n",
    "Much like the topic assignment procedure, we iterated over numerous prompts to generate the desired queries. Alongside this, we also employed zero-shot examples to better steer the language model. In this instance, we adjusted the language model's temperature to 0.75 to inspire more creative queries that are less dependent on the zero-shot examples. The produced queries, along with the corresponding article IDs, are saved in a JSON file, enabling subsequent analysis. In addition teh gernal chain and specific chaina re used on the same articles such that comapring the results between these two generated prompts is possible. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5150, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "file = \"Data/cleaned_df.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df = df[df['characters']<=5000]\n",
    "sorted_df = df.sort_values('characters')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and human template in order to generate the queries\n",
    "system_template_general = \"\"\" You are provided with the textual information and the title as well as subtitle of a new article.\n",
    "Your task is to create a Human prompt for the news article, specifically taking into acocount the topics that the article is talking about.\n",
    "The propmt should be general format and not mention specific words or context of the article. Rather conctrate on the general topics described.\n",
    "The prompt must be written in german. The input information is given in german. \n",
    "The different inputs of the news article are seperated by: ####\n",
    "Missing values are indicated by the string: nan\n",
    "\"\"\"\n",
    "\n",
    "system_template_specific = \"\"\" You are provided with the textual information and the title as well as subtitle of a new article.\n",
    "Your task is to create a Human prompt for the news article, specifically taking into acocount the topics that the article is talking about.\n",
    "The propmt should be very specifict. Meaning is I use it in a query it will only return this article and no other. Conctrate on the specific topics described.\n",
    "The prompt must be written in german. The input information is given in german. \n",
    "The different inputs of the news article are seperated by: ####\n",
    "Missing values are indicated by the string: nan\n",
    "\"\"\"\n",
    "\n",
    "human_template = \"\"\" The following is a news article. All the information is given in german.\n",
    "The title of the article:\n",
    "####\n",
    "{title}\n",
    "####\n",
    "The text of the article:\n",
    "####\n",
    "{text}\n",
    "####\n",
    "The general classification given by the dataset:\n",
    "####\n",
    "{general}\n",
    "####\n",
    "The subtitle of the article:\n",
    "####\n",
    "{subtitle}\n",
    "####\n",
    "The supertitle of the article:\n",
    "{dachzeile}\n",
    "###\n",
    "The rubrik and resort of the article:\n",
    "{rubrik}, {resort}\n",
    "####\n",
    "\"\"\"\n",
    "templates_gen = {'system_gen':system_template_general, 'system_spe': system_template_specific, 'human_temp': human_template}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open ('prompt_templates/evals/gen_sys_templates.json', 'w') as handle:\n",
    "        json.dump(templates_gen,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('prompt_templates/evals/gen_sys_templates.json', 'r') as handle:\n",
    "    templates_gen = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the zeros hot example, it is about the yearly earnings of teh News Corp corperation.\n",
    "templates_new = {}\n",
    "idx= 635\n",
    "id = sorted_df.loc[idx,:]['article_id']\n",
    "title = sorted_df.loc[idx,:]['title']\n",
    "subtitle = sorted_df.loc[idx,:]['subtitle']\n",
    "text = sorted_df.loc[idx,:]['paragraphs']\n",
    "rubrik = sorted_df.loc[idx,:]['rubrik']\n",
    "general = sorted_df.loc[idx,:]['general_topic']\n",
    "ressort = sorted_df.loc[idx,:]['ressort']\n",
    "dach = sorted_df.loc[idx,:]['dachzeile']\n",
    "\n",
    "human_example = human_template.format(title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach)\n",
    "\n",
    "ai_example_general = \"Ich such nach einen Artikel über Nachrichtendienste\"\n",
    "ai_example_spec = \"Könntest du Artikel über die Geschäftsentwicklung von der Mediengruppe News Corp anzeigen\"\n",
    "\n",
    "templates_new[id] =[]\n",
    "templates_new[id].append({'human':human_example, 'ai_gen':ai_example_general, 'ai_spec':ai_example_spec})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open ('prompt_templates/evals/gen_templates.json', 'w') as handle:\n",
    "        json.dump(templates_new,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open ('prompt_templates/evals/gen_templates.json', 'r') as handle:\n",
    "        templates_new = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the genration of prompts i set the temperature higher to let the llm be more creative\n",
    "chat = ChatOpenAI(temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt_gen = SystemMessagePromptTemplate.from_template(templates_gen['system_gen'])\n",
    "system_message_prompt_spe = SystemMessagePromptTemplate.from_template(templates_gen['system_spe'])\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(templates_gen['human_temp'])\n",
    "example_human = HumanMessagePromptTemplate.from_template(templates_new['FALTER_20151111C499C672CF'][0]['human'])\n",
    "example_ai_gen = AIMessagePromptTemplate.from_template(templates_new['FALTER_20151111C499C672CF'][0]['ai_gen'])\n",
    "example_ai_spe = AIMessagePromptTemplate.from_template(templates_new['FALTER_20151111C499C672CF'][0]['ai_spec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_gen = ChatPromptTemplate.from_messages([system_message_prompt_gen, example_human, example_ai_gen, human_message_prompt])\n",
    "chain_gen = LLMChain(llm=chat, prompt=chat_prompt_gen)\n",
    "\n",
    "chat_prompt_spe = ChatPromptTemplate.from_messages([system_message_prompt_spe, example_human, example_ai_spe, human_message_prompt])\n",
    "chain_spe = LLMChain(llm=chat, prompt=chat_prompt_spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over generate 100 random propmts, the articles for the general and specific set are the same in order to be able to compare them\n",
    "# No article is selected twice to keep diveristy.\n",
    "\n",
    "if False:\n",
    "    general_eval_set = {}\n",
    "    spe_eval_set = {}\n",
    "\n",
    "    used_indices = set()\n",
    "\n",
    "    for i in range(100):\n",
    "        idx = random.randint(0,df.shape[0]-1)\n",
    "        while idx in used_indices:\n",
    "            idx = random.randint(0, df.shape[0] - 1)\n",
    "\n",
    "        used_indices.add(idx)\n",
    "        id = sorted_df.loc[idx,:]['article_id']\n",
    "        title = sorted_df.loc[idx,:]['title']\n",
    "        subtitle = sorted_df.loc[idx,:]['subtitle']\n",
    "        text = sorted_df.loc[idx,:]['paragraphs']\n",
    "        rubrik = sorted_df.loc[idx,:]['rubrik']\n",
    "        general = sorted_df.loc[idx,:]['general_topic']\n",
    "        ressort = sorted_df.loc[idx,:]['ressort']\n",
    "        dach = sorted_df.loc[idx,:]['dachzeile']\n",
    "\n",
    "        result_gen = chain_gen.run(title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach)\n",
    "        result_spe = chain_spe.run(title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach)\n",
    "\n",
    "\n",
    "        general_eval_set[i]=[{'prompt':result_gen, 'answer':id}]\n",
    "        spe_eval_set[i]=[{'prompt':result_spe, 'answer':id}]\n",
    "\n",
    "\n",
    "    with open ('evals/general_prompts.json', 'w') as handle:\n",
    "        json.dump(general_eval_set, handle)\n",
    "\n",
    "    with open ('evals/specific_prompts.json', 'w') as handle:\n",
    "        json.dump(spe_eval_set, handle)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('prompt_templates/evals/general_prompts.json', 'r') as handle:\n",
    "        general_eval_set = json.load(handle)\n",
    "\n",
    "with open ('prompt_templates/evals/specific_prompts.json', 'r') as handle:\n",
    "        spe_eval_set = json.load( handle)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Query Evaluation and Refinement\n",
    "\n",
    "While the queries generated in the previous section serve as a good starting point, merely evaluating recommendations based on the match between the article IDs of the base articles can be overly restrictive. This is due to the fact that articles might cover similar topics, making them relevant recommendations nonetheless. Hence, we designed a language model pipeline that takes a query and the recommended news article, assessing the relevance of the news article to the query. We developed two evaluation chains: one lenient and one stricter. These chains allow us to gauge the quality of the generated queries. The generic queries achieved a relevance score of 88 in the standard evaluation system and 99 in the more relaxed system. Similarly, the specific queries achieved relevance scores of 97 and 98, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new chat with low temperature this time we need the llm to be listen to its constructions \n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You are given the information of a news article and a user prompt. \n",
    "You are part of the evaluation system of a recommender system for news articles based on user prompts.\n",
    "More specific the recoomendation system is trying to match user prompts to news articles based on the topics that the user is looking for.\n",
    "Your task is to decide if the recommended article matches the user prompt in terms of the topics that the prompt is looking for.\n",
    "The input information is given in german. \n",
    "The different inputs of the news article are seperated by: ####\n",
    "Missing values are indicated by the string: nan\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "system_template_relaxed = \"\"\"You are given the information of a news article and a user prompt. \n",
    "You are part of the evaluation system of a recommender system for news articles based on user prompts.\n",
    "More specific the recoomendation system is trying to match user prompts to news articles based on the topics that the user is looking for.\n",
    "Your task is to decide if the recommended article matches the user prompt in terms of the topics. In your decision process you are already satisfied if the topics the prompt is looking for are only remotly present in the news article.\n",
    "The input information is given in german. \n",
    "The different inputs of the news article are seperated by: ####\n",
    "Missing values are indicated by the string: nan\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "system_template_relaxed_2 = \"\"\"You are given the information of a news article and a user prompt. \n",
    "You are part of the evaluation system of a recommender system that matches news articles based on user prompts based on topics.\n",
    "Your task is to decide if the recommended article matches the user prompt in terms of the topics that both handle. \n",
    "In your decision process you are already not strict and are already satisfied if the topics the prompt is looking for are only slightly present in the news article.\n",
    "The input information is given in german. \n",
    "The different inputs of the news article are seperated by: ####\n",
    "Missing values are indicated by the string: nan\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "human_template = \"\"\" The following is a news article and the corrpsoning prompt. All the information is given in german.\n",
    "The title of the article:\n",
    "####\n",
    "{title}\n",
    "####\n",
    "The text of the article:\n",
    "####\n",
    "{text}\n",
    "####\n",
    "The general classification given by the dataset:\n",
    "####\n",
    "{general}\n",
    "####\n",
    "The subtitle of the article:\n",
    "####\n",
    "{subtitle}\n",
    "####\n",
    "The supertitle of the article:\n",
    "{dachzeile}\n",
    "###\n",
    "The rubrik and resort of the article:\n",
    "{rubrik}, {resort}\n",
    "####\n",
    "Finally the propmt:\n",
    "{prompt}\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "description = \"Matches the recommended news article the given prompt in terms of topics of the news article that the user prompt is looking for  ? \\\n",
    "                            Answer True if yes,\\\n",
    "                            False if not or unknown.\"\n",
    "\n",
    "description_relaxed = \"Matches the recommended news article the given prompt in terms of topics of the news article that the user prompt is looking for in the slightest sense? \\\n",
    "                            Answer True if yes,\\\n",
    "                            False if not or unknown.\"\n",
    "\n",
    "description_relaxed_2 = \"Matches the recommended news article the given prompt in terms of topics of the news article that the user prompt is looking for in the slightest sense? \\\n",
    "                            Answer True if yes,\\\n",
    "                            False if not or unknown.\"\n",
    "\n",
    "templates = {'system': system_template, 'system_relaxed':system_template_relaxed, 'system_relaxed_2':system_template_relaxed_2, 'human':human_template, 'schema': description, 'schema_relaxed' : description_relaxed, 'schema_relaxed_2' : description_relaxed_2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open('prompt_templates/evals/eval_templates.json', 'w') as handle:\n",
    "        json.dump(templates, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt_templates/evals/eval_templates.json', 'r') as handle:\n",
    "        templates = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the schema makes the output uniform and we can simply return a dictionary\n",
    "relevance_schema = ResponseSchema(name=\"relevance\",\n",
    "                            description=templates['schema'])\n",
    "                                                  \n",
    "relevance_schema_rel = ResponseSchema(name=\"relevance\",\n",
    "                            description=templates['schema_relaxed_2'])\n",
    "\n",
    "response_schemas = [relevance_schema]\n",
    "response_schemas_rel = [relevance_schema_rel]\n",
    "                                                  \n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser_rel = StructuredOutputParser.from_response_schemas(response_schemas_rel)\n",
    "\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions_rel = output_parser_rel.get_format_instructions()\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(templates['system'])\n",
    "system_message_prompt_rel = SystemMessagePromptTemplate.from_template(templates['system_relaxed_2'])\n",
    "                                                  \n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(templates['human'])\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt_rel = ChatPromptTemplate.from_messages([system_message_prompt_rel, human_message_prompt])\n",
    "                                                  \n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chain_rel = LLMChain(llm=chat, prompt=chat_prompt_rel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation of the Prompts and the normal Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 03 Jul 2023 13:34:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7e0f7a00ad4b2fb9-VIE', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the whole General prompts set and the strict evaluation\n",
    "# Carful costs a lot of money and takes about 10 minutes\n",
    "ovr_results_gen = []\n",
    "for i in range(len(general_eval_set)):\n",
    "    prompt = general_eval_set[str(i)][0]['prompt']\n",
    "    id = general_eval_set[str(i)][0]['answer']\n",
    "    matching_row = df[df['article_id'] == id]\n",
    "\n",
    "\n",
    "    title = matching_row['title'].values[0]\n",
    "    subtitle = matching_row['subtitle'].values[0]\n",
    "    text = matching_row['paragraphs'].values[0]\n",
    "    rubrik = matching_row['rubrik'].values[0]\n",
    "    general = matching_row['general_topic'].values[0]\n",
    "    ressort = matching_row['ressort'].values[0]\n",
    "    dach = matching_row['dachzeile'].values[0]\n",
    "\n",
    "    result = chain.run(format_instructions = format_instructions, title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach, prompt = prompt)\n",
    "\n",
    "    result_dict = output_parser.parse(result)\n",
    "    result_dict['id'] = id\n",
    "    ovr_results_gen.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "total_count = len(ovr_results_gen)\n",
    "\n",
    "for entry in ovr_results_gen:\n",
    "    relevance = entry['relevance']\n",
    "    if isinstance(relevance, bool) and relevance:\n",
    "        true_count += 1\n",
    "\n",
    "percentage = (true_count / total_count) * 100\n",
    "\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the whole specific prompts set\n",
    "# Careful costs a lot of money\n",
    "ovr_results_spe = []\n",
    "for i in range(len(spe_eval_set)):\n",
    "    prompt = spe_eval_set[str(i)][0]['prompt']\n",
    "    id = spe_eval_set[str(i)][0]['answer']\n",
    "    matching_row = df[df['article_id'] == id]\n",
    "    title = matching_row['title'].values[0]\n",
    "    subtitle = matching_row['subtitle'].values[0]\n",
    "    text = matching_row['paragraphs'].values[0]\n",
    "    rubrik = matching_row['rubrik'].values[0]\n",
    "    general = matching_row['general_topic'].values[0]\n",
    "    ressort = matching_row['ressort'].values[0]\n",
    "    dach = matching_row['dachzeile'].values[0]\n",
    "\n",
    "    result = chain.run(format_instructions = format_instructions, title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach, prompt = prompt)\n",
    "\n",
    "    result_dict = output_parser.parse(result)\n",
    "    result_dict['id'] = id\n",
    "    ovr_results_spe.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.0\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "total_count = len(ovr_results_spe)\n",
    "\n",
    "for entry in ovr_results_spe:\n",
    "    relevance = entry['relevance']\n",
    "    if isinstance(relevance, bool) and relevance:\n",
    "        true_count += 1\n",
    "\n",
    "percentage = (true_count / total_count) * 100\n",
    "\n",
    "print(percentage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation with the Prompts and the Relaxed Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the whole General prompts set and the strict evaluation\n",
    "# Carful costs a lot of money and takes about 10 minutes\n",
    "ovr_results_gen = []\n",
    "for i in range(len(general_eval_set)):\n",
    "    prompt = general_eval_set[str(i)][0]['prompt']\n",
    "    id = general_eval_set[str(i)][0]['answer']\n",
    "    matching_row = df[df['article_id'] == id]\n",
    "\n",
    "\n",
    "    title = matching_row['title'].values[0]\n",
    "    subtitle = matching_row['subtitle'].values[0]\n",
    "    text = matching_row['paragraphs'].values[0]\n",
    "    rubrik = matching_row['rubrik'].values[0]\n",
    "    general = matching_row['general_topic'].values[0]\n",
    "    ressort = matching_row['ressort'].values[0]\n",
    "    dach = matching_row['dachzeile'].values[0]\n",
    "\n",
    "    result = chain_rel.run(format_instructions = format_instructions_rel, title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach, prompt = prompt)\n",
    "\n",
    "    result_dict = output_parser.parse(result)\n",
    "    result_dict['id'] = id\n",
    "    ovr_results_gen.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "total_count = len(ovr_results_gen)\n",
    "\n",
    "for entry in ovr_results_gen:\n",
    "    relevance = entry['relevance']\n",
    "    if isinstance(relevance, bool) and relevance:\n",
    "        true_count += 1\n",
    "\n",
    "percentage = (true_count / total_count) * 100\n",
    "\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the whole specific prompts set\n",
    "# Careful costs a lot of money\n",
    "ovr_results_spe = []\n",
    "for i in range(len(spe_eval_set)):\n",
    "    prompt = spe_eval_set[str(i)][0]['prompt']\n",
    "    id = spe_eval_set[str(i)][0]['answer']\n",
    "    matching_row = df[df['article_id'] == id]\n",
    "    title = matching_row['title'].values[0]\n",
    "    subtitle = matching_row['subtitle'].values[0]\n",
    "    text = matching_row['paragraphs'].values[0]\n",
    "    rubrik = matching_row['rubrik'].values[0]\n",
    "    general = matching_row['general_topic'].values[0]\n",
    "    ressort = matching_row['ressort'].values[0]\n",
    "    dach = matching_row['dachzeile'].values[0]\n",
    "\n",
    "    result = chain_rel.run(format_instructions = format_instructions_rel, title = title, subtitle = subtitle,text=text, rubrik = rubrik, resort=ressort, general=general, dachzeile=dach, prompt = prompt)\n",
    "\n",
    "    result_dict = output_parser.parse(result)\n",
    "    result_dict['id'] = id\n",
    "    ovr_results_spe.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "total_count = len(ovr_results_spe)\n",
    "\n",
    "for entry in ovr_results_spe:\n",
    "    relevance = entry['relevance']\n",
    "    if isinstance(relevance, bool) and relevance:\n",
    "        true_count += 1\n",
    "\n",
    "percentage = (true_count / total_count) * 100\n",
    "\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
